{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b960add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imort libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity;\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import sys\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "994d86f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function define for read text files\n",
    "def read_text_doc(text_document): \n",
    "    text_data =  open(text_document).read()\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f37cb3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the text file data\n",
    "Doc01=read_text_doc(\"doc 1.txt\")\n",
    "Doc02=read_text_doc(\"doc 2.txt\")\n",
    "Doc03=read_text_doc(\"doc 3.txt\")\n",
    "Doc04=read_text_doc(\"doc 4.txt\")\n",
    "Doc05=read_text_doc(\"doc 5.txt\")\n",
    "Doc06=read_text_doc(\"doc 6.txt\")\n",
    "Doc07=read_text_doc(\"doc 7.txt\")\n",
    "Doc08=read_text_doc(\"doc 8.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c73d6c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a single text data file\n",
    "All_Doc=[Doc01,Doc02,Doc03,Doc04,Doc05,Doc06,Doc07,Doc08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b9c567db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.54082435 0.42279101 0.56849572 0.50821448 0.48433927\n",
      "  0.5472568  0.59938462]\n",
      " [0.54082435 1.         0.68250002 0.61184088 0.53099415 0.53330571\n",
      "  0.84194483 0.50997942]\n",
      " [0.42279101 0.68250002 1.         0.4670546  0.40854181 0.41944037\n",
      "  0.65355313 0.3833241 ]\n",
      " [0.56849572 0.61184088 0.4670546  1.         0.74806744 0.7313034\n",
      "  0.61104358 0.54061195]\n",
      " [0.50821448 0.53099415 0.40854181 0.74806744 1.         0.55023635\n",
      "  0.53310933 0.45222212]\n",
      " [0.48433927 0.53330571 0.41944037 0.7313034  0.55023635 1.\n",
      "  0.52849343 0.46656382]\n",
      " [0.5472568  0.84194483 0.65355313 0.61104358 0.53310933 0.52849343\n",
      "  1.         0.51410949]\n",
      " [0.59938462 0.50997942 0.3833241  0.54061195 0.45222212 0.46656382\n",
      "  0.51410949 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF vector \n",
    "TF_DF_vector=TfidfVectorizer();\n",
    "#TF-IDF values is found for all text\n",
    "TF_DF_vector_Tansform= TF_DF_vector.fit_transform(All_Doc, y=None);\n",
    "# cosine similarity matrix\n",
    "Cos_sim_matrix = cosine_similarity(TF_DF_vector_Tansform);\n",
    "print(Cos_sim_matrix);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fc159e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540824</td>\n",
       "      <td>0.422791</td>\n",
       "      <td>0.568496</td>\n",
       "      <td>0.508214</td>\n",
       "      <td>0.484339</td>\n",
       "      <td>0.547257</td>\n",
       "      <td>0.599385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.540824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.611841</td>\n",
       "      <td>0.530994</td>\n",
       "      <td>0.533306</td>\n",
       "      <td>0.841945</td>\n",
       "      <td>0.509979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.422791</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.467055</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>0.419440</td>\n",
       "      <td>0.653553</td>\n",
       "      <td>0.383324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.568496</td>\n",
       "      <td>0.611841</td>\n",
       "      <td>0.467055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.748067</td>\n",
       "      <td>0.731303</td>\n",
       "      <td>0.611044</td>\n",
       "      <td>0.540612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.508214</td>\n",
       "      <td>0.530994</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>0.748067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.550236</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>0.452222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.484339</td>\n",
       "      <td>0.533306</td>\n",
       "      <td>0.419440</td>\n",
       "      <td>0.731303</td>\n",
       "      <td>0.550236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528493</td>\n",
       "      <td>0.466564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.547257</td>\n",
       "      <td>0.841945</td>\n",
       "      <td>0.653553</td>\n",
       "      <td>0.611044</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>0.528493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.599385</td>\n",
       "      <td>0.509979</td>\n",
       "      <td>0.383324</td>\n",
       "      <td>0.540612</td>\n",
       "      <td>0.452222</td>\n",
       "      <td>0.466564</td>\n",
       "      <td>0.514109</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.540824  0.422791  0.568496  0.508214  0.484339  0.547257   \n",
       "1  0.540824  1.000000  0.682500  0.611841  0.530994  0.533306  0.841945   \n",
       "2  0.422791  0.682500  1.000000  0.467055  0.408542  0.419440  0.653553   \n",
       "3  0.568496  0.611841  0.467055  1.000000  0.748067  0.731303  0.611044   \n",
       "4  0.508214  0.530994  0.408542  0.748067  1.000000  0.550236  0.533109   \n",
       "5  0.484339  0.533306  0.419440  0.731303  0.550236  1.000000  0.528493   \n",
       "6  0.547257  0.841945  0.653553  0.611044  0.533109  0.528493  1.000000   \n",
       "7  0.599385  0.509979  0.383324  0.540612  0.452222  0.466564  0.514109   \n",
       "\n",
       "          7  \n",
       "0  0.599385  \n",
       "1  0.509979  \n",
       "2  0.383324  \n",
       "3  0.540612  \n",
       "4  0.452222  \n",
       "5  0.466564  \n",
       "6  0.514109  \n",
       "7  1.000000  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarity matrix with in data fram\n",
    "cos_simM=pd.DataFrame(cosine_similarity(TF_DF_vector_Tansform,TF_DF_vector_Tansform))\n",
    "cos_simM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a6201d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 931)\t0.027662736706493843\n",
      "  (0, 839)\t0.023183532292242934\n",
      "  (0, 1404)\t0.023183532292242934\n",
      "  (0, 831)\t0.055325473412987686\n",
      "  (0, 1383)\t0.027662736706493843\n",
      "  (0, 853)\t0.02764673457069204\n",
      "  (0, 1256)\t0.012348235661627424\n",
      "  (0, 201)\t0.027662736706493843\n",
      "  (0, 1355)\t0.02000548618406063\n",
      "  (0, 145)\t0.02000548618406063\n",
      "  (0, 960)\t0.027662736706493843\n",
      "  (0, 1202)\t0.027662736706493843\n",
      "  (0, 480)\t0.027662736706493843\n",
      "  (0, 324)\t0.055325473412987686\n",
      "  (0, 1384)\t0.027662736706493843\n",
      "  (0, 635)\t0.027662736706493843\n",
      "  (0, 1393)\t0.027662736706493843\n",
      "  (0, 112)\t0.027662736706493843\n",
      "  (0, 306)\t0.027662736706493843\n",
      "  (0, 1061)\t0.027662736706493843\n",
      "  (0, 414)\t0.027662736706493843\n",
      "  (0, 1060)\t0.027662736706493843\n",
      "  (0, 576)\t0.027662736706493843\n",
      "  (0, 929)\t0.023183532292242934\n",
      "  (0, 19)\t0.02000548618406063\n",
      "  :\t:\n",
      "  (7, 334)\t0.05035481933727337\n",
      "  (7, 1175)\t0.025177409668636686\n",
      "  (7, 1041)\t0.20141927734909348\n",
      "  (7, 150)\t0.013410233782264778\n",
      "  (7, 1074)\t0.09597736486948943\n",
      "  (7, 884)\t0.07553222900591006\n",
      "  (7, 773)\t0.025177409668636686\n",
      "  (7, 501)\t0.07553222900591006\n",
      "  (7, 460)\t0.07553222900591006\n",
      "  (7, 85)\t0.07553222900591006\n",
      "  (7, 1272)\t0.016861604686529214\n",
      "  (7, 483)\t0.060048930724786544\n",
      "  (7, 502)\t0.04798868243474472\n",
      "  (7, 1251)\t0.49188399495613333\n",
      "  (7, 636)\t0.20395190034766505\n",
      "  (7, 883)\t0.05035481933727337\n",
      "  (7, 770)\t0.20141927734909348\n",
      "  (7, 108)\t0.04023070134679434\n",
      "  (7, 87)\t0.20395190034766505\n",
      "  (7, 1235)\t0.05035481933727337\n",
      "  (7, 1275)\t0.19195472973897887\n",
      "  (7, 1314)\t0.02399434121737236\n",
      "  (7, 722)\t0.025177409668636686\n",
      "  (7, 877)\t0.059985853043430896\n",
      "  (7, 871)\t0.17995755913029268\n"
     ]
    }
   ],
   "source": [
    "print(TF_DF_vector_Tansform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "5102acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Identify_doc_topic(Topicname):\n",
    "    Topic_trans = str.maketrans(string.punctuation+string.ascii_uppercase,\n",
    "                                \" \"*len(string.punctuation)+string.ascii_lowercase)\n",
    "      \n",
    "    Topicname = Topicname.translate(Topic_trans)\n",
    "    Topicname=Topicname.split()\n",
    "    #Topicname = Topicname[int('1')]\n",
    "    limit=len(Topicname)-1\n",
    "\n",
    "\n",
    "\n",
    "    ST = pd.DataFrame([TF_IDF[Topicname[0]], TF_IDF[Topicname[1]], TF_IDF[Topicname[2]], TF_IDF[Topicname[3]]\n",
    "                              + TF_IDF[Topicname[3-1]] + TF_IDF[Topicname[3]]]\n",
    "                             ,index=[Topicname[0], Topicname[1], Topicname[2], Topicname[0] +Topicname[1] +Topicname[2]]).T\n",
    "    ST = ST[ST[Topicname[0]+ Topicname[1]+ Topicname[2]] > 0]\n",
    "    ST = ST[ST[Topicname[0]] > 0]\n",
    "    ST\n",
    "    output = ST.sort_values([Topicname[0]+ Topicname[1]+ Topicname[2]], ascending=[True])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "49487536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hurricane</th>\n",
       "      <th>gilbert</th>\n",
       "      <th>heads</th>\n",
       "      <th>hurricanegilbertheads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.222747</td>\n",
       "      <td>0.102806</td>\n",
       "      <td>0.019856</td>\n",
       "      <td>0.019856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.251965</td>\n",
       "      <td>0.096910</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.210657</td>\n",
       "      <td>0.175548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hurricane   gilbert     heads  hurricanegilbertheads\n",
       "1   0.222747  0.102806  0.019856               0.019856\n",
       "6   0.251965  0.096910  0.022461               0.022461\n",
       "2   0.210657  0.175548  0.000000               0.097096"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic01='Hurricane Gilbert Heads Toward Dominican Coast'\n",
    "Identify_doc_topic(topic01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba07f57",
   "metadata": {},
   "source": [
    "The document 2, 3,7 are related to the \n",
    "topic of \"Hurricane Gilbert Heads Toward Dominican Coast\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c0e74855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "f=TfidfVectorizer();\n",
    "def boring_tokenizer(input_word):\n",
    "    term = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", input_word).lower().split()\n",
    "    return term\n",
    "\n",
    "def find_topic_in_doc(topic_name,n):\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', tokenizer=boring_tokenizer)\n",
    "    X = count_vectorizer.fit_transform(topic_name)\n",
    "    Topicname=count_vectorizer.get_feature_names()\n",
    "    N=len(Topicname) \n",
    "     \n",
    "    best_word = Topicname[n].split()\n",
    "    count = TF_DF_vector.vocabulary_[Topicname[n]]\n",
    "    \n",
    "    idf_df = np.transpose(TF_DF_vector_Tansform[:,count])\n",
    "    print('The no of words in topic',N)\n",
    "    print(\"The considering word in topic\",best_word)\n",
    "    print('TF-IDF values for the best identifying word \\n', np.transpose(TF_DF_vector_Tansform[:,count]))\n",
    "    \n",
    "    \n",
    "\n",
    "topic01=['Hurricane Gilbert Heads Toward Dominican Coast']\n",
    "topic02= [\"McDonald's Opens First Restaurant in China\"]\n",
    "topic03=['ira terrorist attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "1359ee70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of words in topic 5\n",
      "The considering word in topic ['coast']\n",
      "TF-IDF values for the best identifying word \n",
      " [[0.         0.05140311 0.17554786 0.         0.         0.\n",
      "  0.07752765 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "find_topic_in_doc(topic01,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "0ca1a807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of words in topic 5\n",
      "The considering word in topic ['dominican']\n",
      "TF-IDF values for the best identifying word \n",
      " [[0.         0.08567184 0.03510957 0.         0.         0.\n",
      "  0.03876382 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "find_topic_in_doc(topic01,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4a33cc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of words in topic 5\n",
      "The considering word in topic ['gilbert']\n",
      "TF-IDF values for the best identifying word \n",
      " [[0.         0.10280621 0.17554786 0.         0.         0.\n",
      "  0.09690956 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "find_topic_in_doc(topic01,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "cb874316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of words in topic 5\n",
      "The considering word in topic ['heads']\n",
      "TF-IDF values for the best identifying word \n",
      " [[0.         0.01985631 0.         0.         0.         0.\n",
      "  0.0224609  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "find_topic_in_doc(topic01,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "77d92792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of words in topic 3\n",
      "The considering word in topic ['attack']\n",
      "TF-IDF values for the best identifying word \n",
      " [[0.         0.         0.         0.07037692 0.         0.03123956\n",
      "  0.         0.02172604]]\n"
     ]
    }
   ],
   "source": [
    "find_topic_in_doc(topic03,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "dbb09a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of words in topic 3\n",
      "The considering word in topic ['ira']\n",
      "TF-IDF values for the best identifying word \n",
      " [[0.         0.         0.         0.16311382 0.         0.07240448\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "find_topic_in_doc(topic03,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "bfff8d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of words in topic 5\n",
      "The considering word in topic ['restaurant']\n",
      "TF-IDF values for the best identifying word \n",
      " [[0.09273413 0.         0.         0.         0.         0.\n",
      "  0.         0.20141928]]\n"
     ]
    }
   ],
   "source": [
    "find_topic_in_doc(topic02,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e2e43231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of words in topic 5\n",
      "The considering word in topic ['mcdonald']\n",
      "TF-IDF values for the best identifying word \n",
      " [[0.23183532 0.         0.         0.         0.         0.\n",
      "  0.         0.20141928]]\n"
     ]
    }
   ],
   "source": [
    "find_topic_in_doc(topic02,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9357c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e3783e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
